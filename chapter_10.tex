\documentclass[a4paper]{report}
\usepackage{amsmath}

\usepackage{hyperref}

\setcounter{chapter}{9}

\renewcommand{\vec}[1]{{\boldsymbol{#1}}}
\newcommand{\tvec}[2]{{\vec{#1}^{(#2)}}}
\newcommand{\svec}[2]{{\vec{#1}_{#2}}}
\newcommand{\stvec}[3]{{\vec{#1}_{#2}^{(#3)}}}

\begin{document}
\chapter{Questions for Sequence Modelling: Recurrent and Recursive Nets}

\section{Questions for Unfolding Computational Graphs}

  \subsection{} The authors state that \textit{"Much as almost any function can be considered a feed forward neural network, essentially any function involving recurrence can be considered a recurrent neural network."} Do you agree with this statement?
  \subsection{} When predicting the future from the past, an RNN learns to use its hidden state to summarize the history of observations. This is in general a necessarily lossy summary, since the history sequence can be any length and the hidden state is finite. Give an example when this is irrelevant for the prediction task. Give an example when this make a big Difference.
    \subsection{}  The unfolded view of a neural network illustrate how information flows forward in time. Is this necessarily the same time direction as in the data (i.e. from an observed time-series)? If yes, explain why. If no, give a counter-example.
    \subsection{}  If we were to imagine neural networks as implementing algorithms using a \href{https://en.wikipedia.org/wiki/Control-flow_graph}{Control-Flow Graph}, how would you characterize the difference between the GFG implemented by a Feed forward Neural Networks compared to a Recurrent Neural Networks?

\section{Questions for Recurrent Neural Networks}

\subsection{} The authors assume hyperbolic tangent units, not ReLU which in earlier chapters has been the most common one. Why do you think that is?

\subsection{} What is the fundamental difference between the two deep RNNs described by the equations \ref{IIR} and \ref{FIR} below?

  \begin{equation}
    \label{IIR}
\begin{gathered}
  \stvec{h}{1}{t} = \tanh(\vec{b}_1 + W_1 \stvec{h}{1}{t-1} + U_1\tvec{x}{t})\\
  \stvec{h}{2}{t} = \tanh(\vec{b}_2 + W_2 \stvec{h}{2}{t-1} + U_2\stvec{h}{1}{t})\\
  \vdots \\
    \stvec{h}{l}{t} = \tanh(\vec{b}_l + W_l \stvec{h}{l}{t-1} + U_l\stvec{h}{l-1}{t})\\
    \tvec{o}{t} = c + V\stvec{h}{l}{t}
\end{gathered}
\end{equation}

  \vspace{10mm}

  \begin{equation}
    \label{FIR}
\begin{gathered}
  \stvec{h}{1}{t} = \tanh(\vec{b}_1 + W_1 \tvec{x}{t-1} + U_1\tvec{x}{t})\\
  \stvec{h}{2}{t} = \tanh(\vec{b}_2 + W_2 \stvec{h}{1}{t-1} + U_2\stvec{h}{1}{t})\\
  \vdots \\
    \stvec{h}{l}{t} = \tanh(\vec{b}_l + W_l \stvec{h}{l-1}{t-1} + U_l\stvec{h}{l-1}{t})\\
    \tvec{o}{t} = c + V\stvec{h}{l}{t}
\end{gathered}
\end{equation}

  \subsection{} Below (\ref{NLL}) is a reproduction of equation 10.14 from the book. Under what independence assumptions is it modelling the joint probability $P(y^{(1)}, y^{(2)}, \ldots, y^{(1)})$?

  \begin{equation}
    \label{NLL}
    \begin{gathered}
      -\sum_t \log p_{\text{model}}(y^{(t)} | \{\tvec{x}{1}, \tvec{x}{2}, \ldots, \tvec{x}{t}\}
\end{gathered}
\end{equation}

  \subsection{}
  A common setup for training RNNs on sequence data (text and time-series) is to use next-step prediction (see equation \ref{NSP} below). In what way (if any) is this different from the network described by figure 10.4 of the book, and is it an application of teacher forcing?

  \begin{equation}
    \label{NSP}
    \begin{gathered}
      \tvec{h}{t} = \tanh(\vec{b} + W \tvec{h}{t-1} + U\tvec{x}{t})\\
    \tvec{o}{t} = \vec{c} + V\tvec{h}{t}\\
    \tvec{y}{t} = \text{softmax}(\tvec{o}{t})\\
    L^{(t)} = -\log p_{\text{model}}(\tvec{x}{t+1} | \tvec{o}{t})
\end{gathered}
\end{equation}


\end{document}
