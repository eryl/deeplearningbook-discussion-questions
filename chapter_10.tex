\documentclass[a4paper]{report}
\usepackage{amsmath}

\usepackage{hyperref}

\setcounter{chapter}{9}

\renewcommand{\vec}[1]{{\boldsymbol{#1}}}
\newcommand{\tvec}[2]{{\vec{#1}^{(#2)}}}
\newcommand{\svec}[2]{{\vec{#1}_{#2}}}
\newcommand{\stvec}[3]{{\vec{#1}_{#2}^{(#3)}}}

\begin{document}
\chapter{Sequence Modelling: Recurrent and Recursive Nets}

\section{Unfolding Computational Graphs}

  \subsection{} The authors state that "Much as almost any function can be considered a feedforward neural network, essentially any function involving recurrence can be considered a recurrent neural network." Do you agree with this satement?
  \subsection{} When predicting the future from the past, an RNN learns to use it's hidden state to summarize the history of observations. This is in general a necessarily lossy summary, since the history sequency can be any length and the hidden state is finite. Give an example when this is irrelevant for the prediction task. Give an example when this make a huge difference.
    \subsection{}  The unfolded view of a neural network illustrate how information flows forward in time. Is this necessarily the same time direction as in the data (i.e. from an observed time-series)? If yes, explain why. If no, give a counter-example.
    \subsection{}  If we were to imagine neural networks as implementing algorithms using a \href{https://en.wikipedia.org/wiki/Control-flow_graph}{Control-Flow Graph}, how would you characterize the difference between the GFG implemented by a Feedforward Neural Networks compared to a Recurrent Neural Networks?

\section{Recurrent Neural Networks}

\subsection{} The authors assume hyperbolical tangent units, not ReLU which in earlier chapters has been the most common one. Why do you think that is?

\subsection{} What is the fundamental difference between the two deep RNNs described by the equations \ref{IIR} and \ref{FIR} below?

  \begin{equation}
    \label{IIR}
\begin{gathered}
  \stvec{h}{1}{t} = \tanh(\vec{b}_1 + W_1 \stvec{h}{1}{t-1} + U_1\tvec{x}{t})\\
  \stvec{h}{2}{t} = \tanh(\vec{b}_2 + W_2 \stvec{h}{2}{t-1} + U_2\stvec{h}{1}{t})\\
  \vdots \\
    \stvec{h}{l}{t} = \tanh(\vec{b}_l + W_l \stvec{h}{l}{t-1} + U_l\stvec{h}{l-1}{t})\\
    \tvec{o}{t} = c + V\stvec{h}{l}{t}
\end{gathered}
\end{equation}

  \vspace{10mm}

  \begin{equation}
    \label{FIR}
\begin{gathered}
  \stvec{h}{1}{t} = \tanh(\vec{b}_1 + W_1 \tvec{x}{t-1} + U_1\tvec{x}{t})\\
  \stvec{h}{2}{t} = \tanh(\vec{b}_2 + W_2 \stvec{h}{1}{t-1} + U_2\stvec{h}{1}{t})\\
  \vdots \\
    \stvec{h}{l}{t} = \tanh(\vec{b}_l + W_l \stvec{h}{l-1}{t-1} + U_l\stvec{h}{l-1}{t})\\
    \tvec{o}{t} = c + V\stvec{h}{l}{t}
\end{gathered}
\end{equation}

  \subsection{} Below (\ref{NLL}) is a reproduction of equation 10.14 from the book. Under what independence assumptions is it modelling the joint probability $P(y^{(1)}, y^{(2)}, \ldots, y^{(1)})$?

  \begin{equation}
    \label{NLL}
    \begin{gathered}
      -\sum_t \log p_{\text{model}}(y^{(t)} | \{\tvec{x}{1}, \tvec{x}{2}, \ldots, \tvec{x}{t}\}
\end{gathered}
\end{equation}

  \subsection{}
  A common setup for training RNNs on sequence data (text and time-series) is to use next-step prediction (see equation \ref{NSP} below). In what way (if any) is this different from the network described by figure 10.4 of the book, and is it an application of teacher forcing?

  \begin{equation}
    \label{NSP}
    \begin{gathered}
      \tvec{h}{t} = \tanh(\vec{b} + W \tvec{h}{t-1} + U\tvec{x}{t})\\
    \tvec{o}{t} = \vec{c} + V\tvec{h}{t}\\
    \tvec{y}{t} = \text{softmax}(\tvec{o}{t})\\
    L^{(t)} = -\log p_{\text{model}}(\tvec{x}{t+1} | \tvec{o}{t})
\end{gathered}
\end{equation}


\end{document}
