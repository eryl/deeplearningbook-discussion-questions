# Chapter 9
## Chapter 9.1
1. Why does w(t) need to be a valid probability density function for the output to be a weighted average?
2. Why is the output of a convolution in the neural networks community referred to as a feature map?
3. Why is it not as important to flip the kernel for convolutions in neural networks?
4. In many machine learning libraries, the convolution operator is actually implemented as cross-correlation. When could this be an issue?
5. Write down the matrix corresponding to the convolution x*w, where x is a 4x4 matrix and w is a 2x2 kernel.


